# src/app/infra/llm/dummy.py

from typing import List, Optional

from app.common.messages import Message
from app.infra.llm.base import LLMClient


class DummyLLMClient:
    """
    ä¸€ä¸ªâ€œå‡â€çš„ LLM å®ç°ï¼Œç”¨æ¥åœ¨è¿˜æ²¡æ¥å…¥ vLLM æ—¶æ‰“é€šæµç¨‹ã€‚

    è¡Œä¸ºï¼š
    - æ‰¾åˆ°æœ€åä¸€æ¡ user æ¶ˆæ¯
    - è¿”å›ä¸€æ¡ç®€å•çš„â€œæ¨¡æ‹Ÿå›å¤â€
    """

    def chat(self, messages: List[Message]) -> Message:
        last_user: Optional[Message] = None

        for msg in reversed(messages):
            if msg.role == "user":
                last_user = msg
                break

        if last_user is None:
            content = "DummyLLMï¼šè¿˜æ²¡æœ‰æ”¶åˆ°ç”¨æˆ·æ¶ˆæ¯ ğŸ¤”"
        else:
            content = f"DummyLLM æ¨¡æ‹Ÿå›å¤ï¼š{last_user.content}"

        return Message(role="assistant", content=content)
    # ä»¥åæˆ‘ä»¬åªéœ€è¦å†å†™ä¸€ä¸ª VllmLLMClient(LLMClient)ï¼Œæ›¿æ¢æ‰ Dummy å°±è¡Œï¼Œ
    # ä¸Šå±‚ LangGraph å®Œå…¨ä¸ç”¨æ”¹ï¼Œè¿™å°±æ˜¯â€œæ¥å£+ä¾èµ–æ³¨å…¥â€çš„å¥½å¤„ã€‚